{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a9405427-fd03-454a-8550-7f680611c0cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b7b2df31-f7b6-41d5-8880-7a1f393d057f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Deep_Neural_Network:\n",
    "\n",
    "  def create(self,input_size,output_size,hidden_dims,output_type,initializer='random',\n",
    "             seed=None,activation='relu',leaky_relu_slope=0.1):\n",
    "    \"\"\"\n",
    "    The method to define the architecture of Deep Neural Network and initialize weights.\n",
    "\n",
    "    Parameters:\n",
    "\n",
    "    input_size(int)       :   No. of neurons in input layer.\n",
    "    \n",
    "    output_size(int)      :   No. of classes in classification task (2 in case of binary classification,\n",
    "                              modify the dataset accordingly !)\n",
    "                              (or) No. of Target variables in case of regression task.\n",
    "\n",
    "    hidden_dims(int list) :   No. of neurons in hidden layers.\n",
    "\n",
    "    output_type(string)   :   Type of task :\n",
    "                              'classification'  :  Classification (discrete target).\n",
    "                              'regression'      :  Regression (continuous target).\n",
    "\n",
    "    initializer(string)   :   Weight initializer :\n",
    "                              'random'  : Random initialization.\n",
    "                              'xavier'  : Xavier initialization (preferred for tanh activation).\n",
    "                              'he'      : He initialization (preferred for ReLU activation).\n",
    "\n",
    "    seed(int)             :   NumPy seed for random initialization.\n",
    "\n",
    "    activation(string)    :   Activation function for hidden layers. One of the following :\n",
    "                              'linear'  : Linear activation.\n",
    "                              'sigmoid' : Sigmoid activation.\n",
    "                              'tanh'    : Hyberbolic tangent activation.\n",
    "                              'relu'    : Rectified Linear Unit activation.\n",
    "                              'lrelu'   : Leaky Rectified Linear Unit activation.\n",
    "\n",
    "                              Activation function at output layer would be SoftMax for classification\n",
    "                              and Linear for regression.\n",
    "\n",
    "    leaky_relu_slope(int) :   Slope for Leaky ReLU activation.   \n",
    "\n",
    "    \"\"\"\n",
    "    self.layer_dims=[input_size]+hidden_dims+[output_size]\n",
    "    self.W = {}\n",
    "    self.b = {}\n",
    "    self.activation = activation\n",
    "    self.leaky_relu_slope = leaky_relu_slope\n",
    "    self.initializer = initializer\n",
    "    self.output_type = output_type\n",
    "\n",
    "    self.L = len(self.layer_dims)-1\n",
    "\n",
    "    if seed != None:\n",
    "      np.random.seed(seed)\n",
    "\n",
    "    for i in range(self.L):\n",
    "      self.W[i+1] = np.random.randn(self.layer_dims[i+1],self.layer_dims[i])\n",
    "      self.b[i+1] = np.zeros((self.layer_dims[i+1],1))\n",
    "\n",
    "    if self.initializer == 'xavier':\n",
    "      for i in range(self.L):\n",
    "        self.W[i+1] = self.W[i+1]*np.sqrt(1/(self.layer_dims[i]))\n",
    "\n",
    "    elif self.initializer == 'he':\n",
    "      for i in range(self.L):\n",
    "        self.W[i+1] = self.W[i+1]*np.sqrt(2/(self.layer_dims[i]))\n",
    "\n",
    "\n",
    "\n",
    "  def save_weights(self):\n",
    "    \"\"\"\n",
    "    The method to save model weights.\n",
    "\n",
    "    Returns :\n",
    "\n",
    "    params(tuple)   : Tuple containing Model weights and biases in form of dictionaries.\n",
    "\n",
    "    \"\"\"\n",
    "    return (self.W,self.b)\n",
    "\n",
    "  \n",
    "\n",
    "  def load_weights(self,params):\n",
    "    \"\"\"\n",
    "    The method to load model weights.\n",
    "\n",
    "    Parameters :\n",
    "\n",
    "    params(tuple)   : Tuple containing Model weights and biases in form of dictionaries.\n",
    "\n",
    "    \"\"\"\n",
    "    self.W = params[0]\n",
    "    self.b = params[1]\n",
    "\n",
    "\n",
    "\n",
    "  ### ACTIVATION FUNCTIONS AND THEIR GRADIENTS ###\n",
    "\n",
    "  def linear(self,X):\n",
    "    return X\n",
    "\n",
    "  def linear_grad(self,X):\n",
    "    return np.ones(shape=X.shape) \n",
    "\n",
    "  def sigmoid(self,X):\n",
    "    return 1/(1+np.exp(-X))\n",
    "\n",
    "  def sigmoid_grad(self,X):\n",
    "    return self.sigmoid(X)*(1-self.sigmoid(X))\n",
    "\n",
    "  def tanh(self,X):\n",
    "    return np.tanh(X)\n",
    "\n",
    "  def tanh_grad(self,X):\n",
    "    return 1-((self.tanh(X))**2)\n",
    "\n",
    "  def relu(self,X):\n",
    "    return np.maximum(0,X)\n",
    "\n",
    "  def relu_grad(self,X):\n",
    "    return 1.0*(X>0)\n",
    "\n",
    "  def lrelu(self,X):\n",
    "    return np.where(X > 0, X, X * self.leaky_relu_slope)\n",
    "\n",
    "  def lrelu_grad(self,X):\n",
    "    return np.where(X > 0, 1, self.leaky_relu_slope)   \n",
    "\n",
    "  def softmax(self,X):\n",
    "    exps = np.exp(X-np.max(X))\n",
    "    return exps/np.sum(exps,axis=0)\n",
    "\n",
    "\n",
    "\n",
    "  def to_one_hot(self,X):\n",
    "    \"\"\"\n",
    "    The method to convert SoftMax probabilities to label in one hot form.\n",
    "\n",
    "    Parameters :\n",
    "\n",
    "    X(NumPy 2D array of shape (output_size,m))  : Predicted SoftMax probabilities for batch of size m.\n",
    "\n",
    "    Returns :\n",
    "\n",
    "    X_one_hot(NumPy 2D array of shape (output_size,m)) : Predicted labels in one hot form for batch of \n",
    "                                                         size m.\n",
    "\n",
    "    \"\"\"\n",
    "    a = np.argmax(X,axis=0)\n",
    "    b = np.zeros((X.shape[0],a.size))\n",
    "    b[a,np.arange(a.size)] = 1\n",
    "    return b\n",
    "\n",
    "\n",
    "\n",
    "  def accuracy(self,Y_pred,Y_true):\n",
    "    \"\"\"\n",
    "    The method to calculate classification accuracy.\n",
    "\n",
    "    Parameters :\n",
    "\n",
    "    Y_pred(NumPy 2D array of shape (output_size,m))  : Predicted labels for batch of size m.\n",
    "    \n",
    "    Y_true(NumPy 2D array of shape (output_size,m))  : Actual labels for batch of size m.\n",
    "\n",
    "    Returns :\n",
    "\n",
    "    accuracy(float)   : Accuracy in range [0,1].\n",
    "\n",
    "    \"\"\"\n",
    "    a = np.argmax(Y_pred,axis=0)\n",
    "    b = np.argmax(Y_true,axis=0)\n",
    "\n",
    "    correct = np.sum((a==b)*1)\n",
    "    total = a.size\n",
    "\n",
    "    return correct/total\n",
    "\n",
    "\n",
    "\n",
    "  def forward_propagation(self,X,dropout=False):\n",
    "    \"\"\"\n",
    "    The method to forward propagate input data through the network, and calculate activations of \n",
    "    each layer.\n",
    "\n",
    "    Parameters :\n",
    "\n",
    "    X(NumPy 2D array of shape (input_size,m))  : Input data for batch of size m.\n",
    "\n",
    "    dropout(boolean)                           : Perform dropout or not.\n",
    "\n",
    "    Returns :\n",
    "\n",
    "    activations(dictionary)   : Activations of all layers.\n",
    "\n",
    "    \"\"\"\n",
    "    self.Z = {}\n",
    "    self.A = {}\n",
    "\n",
    "    self.A[0] = X\n",
    "\n",
    "    for i in range (len(self.layer_dims)-2):\n",
    "      self.Z[i+1] = np.matmul(self.W[i+1],self.A[i])+self.b[i+1]\n",
    "      _ = \"self.A[i+1] = self.\"+self.activation+\"(self.Z[i+1])\"\n",
    "      exec(_)\n",
    "\n",
    "      if dropout == True:\n",
    "        self.A[i+1] *= ((np.random.rand(self.A[i+1].shape[0],self.A[i+1].shape[1])<self.keep_probs[i])*1)\n",
    "        self.A[i+1].reshape(1,-1)\n",
    "        self.A[i+1] /= self.keep_probs[i]\n",
    "\n",
    "    self.Z[self.L] = np.matmul(self.W[self.L],self.A[len(self.layer_dims)-2])+self.b[self.L]\n",
    "\n",
    "    if self.output_type == 'classification':\n",
    "      self.A[self.L] = self.softmax(self.Z[self.L])\n",
    "\n",
    "    elif self.output_type == 'regression':\n",
    "      self.A[self.L] = self.Z[self.L] \n",
    "\n",
    "    return self.A\n",
    "\n",
    "\n",
    "\n",
    "  def compute_cost(self,Y_pred,Y_true):\n",
    "    \"\"\"\n",
    "    The method to compute cost for the current forward propagated batch.\n",
    "\n",
    "    Parameters :\n",
    "\n",
    "    Y_pred(NumPy 2D array of shape (output_size,m))  : Predicted outputs for current forward propagated \n",
    "                                                       batch of size m.\n",
    "    \n",
    "    Y_true(NumPy 2D array of shape (output_size,m))  : Ground truths for current forward propagated batch\n",
    "                                                       of size m.\n",
    "\n",
    "    Returns :\n",
    "\n",
    "    cost(float)   : Cost for current forward propagated batch.\n",
    "\n",
    "    \"\"\"\n",
    "    if self.output_type=='classification':\n",
    "      cost = (1/Y_true.shape[1])*np.sum(-1*Y_true*np.log(Y_pred))\n",
    "\n",
    "    else:\n",
    "      cost = (1/(2*Y_true.shape[1]))*np.sum((Y_pred-Y_true)**2)\n",
    "\n",
    "    sum=0\n",
    "\n",
    "    if self.regularizer == 'l2':\n",
    "      for i in range(self.L):\n",
    "        sum += np.sum(self.W[i+1]**2)\n",
    "      cost += ((1/(2*Y_true.shape[1]))*sum)      \n",
    "\n",
    "    elif self.regularizer == 'l1':\n",
    "      for i in range(self.L):\n",
    "        sum += np.sum(np.abs(self.W[i+1]))\n",
    "      cost += ((1/Y_true.shape[1])*sum)   \n",
    "    \n",
    "    return cost\n",
    "\n",
    "\n",
    "\n",
    "  def backward_propagation(self,Y):\n",
    "    \"\"\"\n",
    "    The method to compute gradient of cost with respect to weights and biases of each layer.\n",
    "\n",
    "    Parameters :\n",
    "\n",
    "    Y(NumPy 2D array of shape (output_size,m))  : Ground truths for current forward propagated batch \n",
    "                                                  of size m.\n",
    "\n",
    "    Returns :\n",
    "\n",
    "    gradients(tuple)   : Tuple containing gradients of cost with respect to weights and biases of each \n",
    "                         layer in form of dictionaries.\n",
    "\n",
    "    \"\"\"\n",
    "    self.dZ = {}\n",
    "    self.dA = {}\n",
    "    self.dW = {}\n",
    "    self.db = {}\n",
    "\n",
    "    self.dZ[self.L] = self.A[self.L]-Y\n",
    "\n",
    "    for i in range(self.L,0,-1):\n",
    "\n",
    "      self.dW[i] = (1/self.dZ[i].shape[1])*np.matmul(self.dZ[i],self.A[i-1].T)\n",
    "\n",
    "      if self.regularizer == 'l2':\n",
    "        self.dW[i] += self.regularizer_lambda*self.W[i]\n",
    "      elif self.regularizer == 'l1':\n",
    "        self.dW[i] += self.regularizer_lambda*np.where(self.W[i]>0,1,-1) \n",
    "        \n",
    "      self.db[i] = (1/self.dZ[i].shape[1])*np.sum(self.dZ[i],axis=1,keepdims=True)\n",
    "      _ = \"self.dZ[i-1] = np.matmul(self.W[i].T,self.dZ[i])*self.\"+self.activation+\"_grad(self.A[i-1])\"\n",
    "      exec(_) \n",
    "      \n",
    "    return (self.dW,self.db)\n",
    "  \n",
    "\n",
    "\n",
    "  def train(self,X_train,Y_train,X_val,Y_val,optimizer='vanilla',regularizer=None,regularizer_lambda=0.02,\n",
    "            keep_probs=[],mini_batch_size=32,epochs=100,learning_rate=0.01,beta=0.9,beta1=0.9,beta2=0.99,\n",
    "            print_loss_freq=100,plot_loss=True):\n",
    "    \"\"\"\n",
    "    The method to train the weights and biases of each layer for the provided training data with \n",
    "    ground truths.\n",
    "\n",
    "    Parameters :\n",
    "\n",
    "    X_train(NumPy 2D array of shape(input_size,m))   :  Input data(for batch of size m) for training.\n",
    "\n",
    "    Y_train(NumPy 2D array of shape(output_size,m))  :  Ground truths(for batch of size m) for training.\n",
    "\n",
    "    X_val(NumPy 2D array of shape(input_size,m))     :  Input data(for batch of size m) for validation.\n",
    "\n",
    "    Y_val(NumPy 2D array of shape(output_size,m))    :  Ground truths(for batch of size m) for validation.\n",
    "\n",
    "    optimizer(string)             :   Optimizer for training process, one of the following :\n",
    "                                      'vanilla'     : Original gradient decsent.\n",
    "                                      'momentum'    : Gradient descent with momentum.\n",
    "                                      'rmsprop'     : Root mean square propagation.\n",
    "                                      'adam'        : Adaptive moments estimation.\n",
    "    \n",
    "    regularizer(string)           :   Regularizer for weights of network, one of the following :\n",
    "                                      'l1'      : L1 regularization.\n",
    "                                      'l2'      : L2 regularization.\n",
    "                                      'dropout' : Dropout regularization.\n",
    "                                      None      : No regularizer.\n",
    "\n",
    "    regularizer_lambda(float)     :   Regularization parameter lambda for L1 or L2 regularization.\n",
    "\n",
    "    keep_probs(float[0,1] list)   :   Keeping probabilities for hidden layers in Dropout regularization.\n",
    "\n",
    "    mini_batch_size(int)          :   Mini Batch size (1 for Stochastic gradient descent).\n",
    "\n",
    "    epochs(int)                   :   No. of iterations over training set.\n",
    "\n",
    "    learning_rate(float)          :   Learning rate aplha.\n",
    "\n",
    "    beta(float)                   :   Optimizer parameter beta for 'momentum' and 'rmsprop' optimizers.\n",
    "\n",
    "    beta1(float)                  :   Optimizer parameter beta2 for 'adam' optimizer.\n",
    "\n",
    "    beta2(float)                  :   Optimizer parameter beta2 for 'adam' optimizer.\n",
    "\n",
    "    print_loss_freq(int)          :   Frequency of printing metrics.\n",
    "\n",
    "    plot_loss(boolean)            :   Plot learning curves or not.\n",
    "\n",
    "    Returns :\n",
    "\n",
    "    Metrics_history(tuple)        :   History of metrics in form of lists\n",
    "\n",
    "    \"\"\"\n",
    "    self.regularizer_lambda = regularizer_lambda\n",
    "    self.regularizer = regularizer\n",
    "\n",
    "    if keep_probs != []:\n",
    "      self.keep_probs = keep_probs\n",
    "    else:\n",
    "      self.keep_probs = [1]*(len(self.layer_dims)-2)\n",
    "\n",
    "    self.print_loss_freq = print_loss_freq  \n",
    "\n",
    "    self.Mw = {}\n",
    "    self.Mb = {}\n",
    "    self.Vw = {}\n",
    "    self.Vb = {}\n",
    "\n",
    "    for i in range(self.L):\n",
    "      self.Mw[i+1] = np.zeros(shape=self.W[i+1].shape)\n",
    "      self.Mb[i+1] = np.zeros(shape=self.b[i+1].shape)\n",
    "      self.Vw[i+1] = np.zeros(shape=self.W[i+1].shape)\n",
    "      self.Vb[i+1] = np.zeros(shape=self.b[i+1].shape)\n",
    "\n",
    "    train_cost = []\n",
    "    val_cost = []\n",
    "    train_acc = []\n",
    "    val_acc = []\n",
    "    m = X_train.shape[1]\n",
    "\n",
    "    drop = False\n",
    "    if(self.regularizer == 'dropout'):\n",
    "      drop = True\n",
    "\n",
    "    t = 1\n",
    "    \n",
    "    for e in range(epochs):\n",
    "\n",
    "      mask = np.random.permutation(m)\n",
    "\n",
    "      X_train = X_train[:,mask]\n",
    "      Y_train = Y_train[:,mask]\n",
    "\n",
    "      if optimizer == 'vanilla':\n",
    "\n",
    "        for i in range(0,m,mini_batch_size):\n",
    "\n",
    "          _ = self.forward_propagation(X_train[:,i:(i+mini_batch_size)],drop)\n",
    "          _ = self.backward_propagation(Y_train[:,i:(i+mini_batch_size)])\n",
    "          \n",
    "          for i in range(self.L):\n",
    "            self.W[i+1] -= learning_rate*self.dW[i+1]\n",
    "            self.b[i+1] -= learning_rate*self.db[i+1]\n",
    "\n",
    "      elif optimizer == 'momentum':\n",
    "\n",
    "        for i in range(0,m,mini_batch_size):\n",
    "\n",
    "          _ = self.forward_propagation(X_train[:,i:(i+mini_batch_size)],drop)\n",
    "          _ = self.backward_propagation(Y_train[:,i:(i+mini_batch_size)])\n",
    "\n",
    "          for i in range(self.L):\n",
    "            self.Mw[i+1] = (beta*self.Mw[i+1])+(1-beta)*self.dW[i+1]\n",
    "            self.Mb[i+1] = (beta*self.Mb[i+1])+(1-beta)*self.db[i+1]\n",
    "          \n",
    "          \n",
    "          for i in range(self.L):\n",
    "            self.W[i+1] -= learning_rate*self.Mw[i+1]\n",
    "            self.b[i+1] -= learning_rate*self.Mb[i+1]\n",
    "\n",
    "      elif optimizer == 'rmsprop':\n",
    "\n",
    "        for i in range(0,m,mini_batch_size):\n",
    "\n",
    "          _ = self.forward_propagation(X_train[:,i:(i+mini_batch_size)],drop)\n",
    "          _ = self.backward_propagation(Y_train[:,i:(i+mini_batch_size)])\n",
    "\n",
    "          for i in range(self.L):\n",
    "            self.Vw[i+1] = (beta*self.Vw[i+1])+(1-beta)*(self.dW[i+1]**2)\n",
    "            self.Vb[i+1] = (beta*self.Vb[i+1])+(1-beta)*(self.db[i+1]**2)\n",
    "          \n",
    "          for i in range(self.L):\n",
    "            \n",
    "            self.W[i+1] -= learning_rate*(self.dW[i+1]/(np.sqrt(self.Vw[i+1])+10e-8))\n",
    "            self.b[i+1] -= learning_rate*(self.db[i+1]/(np.sqrt(self.Vb[i+1])+10e-8))\n",
    "\n",
    "      elif optimizer == 'adam':\n",
    "        \n",
    "        for i in range(0,m,mini_batch_size):\n",
    "\n",
    "          _ = self.forward_propagation(X_train[:,i:(i+mini_batch_size)],drop)\n",
    "          _ = self.backward_propagation(Y_train[:,i:(i+mini_batch_size)])\n",
    "\n",
    "          for i in range(self.L):\n",
    "\n",
    "            self.Mw[i+1] = (beta1*self.Mw[i+1])+(1-beta1)*self.dW[i+1]\n",
    "            #self.Mw[i+1] /= (1-np.power(beta1,t))\n",
    "            self.Mb[i+1] = (beta1*self.Mb[i+1])+(1-beta1)*self.db[i+1]\n",
    "            #self.Mb[i+1] /= (1-np.power(beta1,t))\n",
    "\n",
    "          for i in range(self.L):\n",
    "            self.Vw[i+1] = (beta2*self.Vw[i+1])+(1-beta2)*(self.dW[i+1]**2)\n",
    "            #self.Vw[i+1] /= (1-np.power(beta2,t))\n",
    "            self.Vb[i+1] = (beta2*self.Vb[i+1])+(1-beta2)*(self.db[i+1]**2)\n",
    "            #self.Vb[i+1] /= (1-np.power(beta2,t))\n",
    "\n",
    "          t += 1  \n",
    "\n",
    "          for i in range(self.L):\n",
    "            self.W[i+1] -= learning_rate*(self.Mw[i+1]/(np.sqrt(self.Vw[i+1])+10e-8))\n",
    "            self.b[i+1] -= learning_rate*(self.Mb[i+1]/(np.sqrt(self.Vb[i+1])+10e-8))\n",
    "\n",
    "      Y_pred_train = self.forward_propagation(X_train)[self.L]\n",
    "      Y_pred_val = self.forward_propagation(X_val)[self.L]\n",
    "                                   \n",
    "      train_cost.append(self.compute_cost(Y_pred_train,Y_train))\n",
    "      val_cost.append(self.compute_cost(Y_pred_val,Y_val))\n",
    "\n",
    "      train_acc.append(self.accuracy(self.to_one_hot(Y_pred_train),Y_train))\n",
    "      val_acc.append(self.accuracy(self.to_one_hot(Y_pred_val),Y_val))\n",
    "\n",
    "      if (e+1)%self.print_loss_freq==0:\n",
    "        if self.output_type == 'classification':\n",
    "          print(\"After \"+str(e+1)+\" epochs :    Training Loss = \"+str(train_cost[e]) +\n",
    "                \"    Validation Loss = \"+str(val_cost[e]) + \"\\n\\n\\t\\t \" +\n",
    "                \"    Training Accuracy = \"+str(train_acc[e]) +\n",
    "                \"    Validation Accuracy = \"+str(val_acc[e])+'\\n')\n",
    "        else:\n",
    "          print(\"After \"+str(e+1)+\" epochs :    Training Loss = \"+str(train_cost[e]) + \n",
    "                \"    Validation Loss = \"+str(val_cost[e])+'\\n')  \n",
    "\n",
    "    if plot_loss == True:\n",
    "\n",
    "      r = list(range(1,epochs+1))\n",
    "      plt.plot(r,train_cost,'r',label=\"Training Loss\")\n",
    "      plt.plot(r,val_cost,'b',label=\"Validation Loss\")\n",
    "      plt.xlabel('Epochs')\n",
    "      if self.output_type == 'regression':\n",
    "        plt.ylabel('L2 Loss')\n",
    "      else:\n",
    "        plt.ylabel('Categorical Cross Entropy Loss') \n",
    "      plt.legend()\n",
    "      plt.show()\n",
    "\n",
    "      print(\"\\nTraining Loss : \",train_cost[-1])\n",
    "      print(\"\\nValidation Loss : \",val_cost[-1]) \n",
    "\n",
    "      if self.output_type == 'classification':\n",
    "        print(\"\\nTraining Accuracy : \",train_acc[-1])\n",
    "        print(\"\\nValidation Accuracy : \",val_acc[-1]) \n",
    "\n",
    "    return (train_cost,val_cost,train_acc,val_acc)       \n",
    "\n",
    "\n",
    "\n",
    "  def predict(self,X):\n",
    "    \"\"\"\n",
    "    The method to predict outputs for given unknown input data.\n",
    "\n",
    "    Parameters :\n",
    "\n",
    "    X(NumPy 2D array of shape (input_size,m))  : Input data for batch of size m.\n",
    "\n",
    "    Returns :\n",
    "\n",
    "    Y_pred(NumPy 2D array of shape (output_size_size,m))  : Predicted output for batch of size m.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    A = self.forward_propagation(X)\n",
    "\n",
    "    if self.output_type == 'regression':\n",
    "      return A[self.L]\n",
    "    else:\n",
    "      return self.to_one_hot(A[self.L])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7527813e-3141-4081-9168-fe488b9304da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import packages\n",
    "\n",
    "from keras.datasets import boston_housing\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d2b031e3-1b95-473e-bd4f-5526ffaaf2a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Boston Housing dataset \n",
    "\n",
    "(X, Y), (X_test, Y_test) = boston_housing.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a05143a1-740f-45e1-9aee-87afbf3618e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          0         1         2         3         4         5         6   \\\n",
      "0   1.000000 -0.192179  0.397419 -0.050828  0.405765 -0.217597  0.344410   \n",
      "1  -0.192179  1.000000 -0.533823 -0.041981 -0.521713  0.338683 -0.578728   \n",
      "2   0.397419 -0.533823  1.000000  0.052839  0.774200 -0.409924  0.656350   \n",
      "3  -0.050828 -0.041981  0.052839  1.000000  0.079803  0.040431  0.080488   \n",
      "4   0.405765 -0.521713  0.774200  0.079803  1.000000 -0.335866  0.729338   \n",
      "5  -0.217597  0.338683 -0.409924  0.040431 -0.335866  1.000000 -0.240875   \n",
      "6   0.344410 -0.578728  0.656350  0.080488  0.729338 -0.240875  1.000000   \n",
      "7  -0.378590  0.650787 -0.725155 -0.083101 -0.777062  0.233970 -0.766670   \n",
      "8   0.609689 -0.311091  0.599226 -0.024851  0.616535 -0.243990  0.462188   \n",
      "9   0.575652 -0.303522  0.701362 -0.051343  0.673471 -0.307904  0.512746   \n",
      "10  0.273447 -0.403139  0.379284 -0.122008  0.188160 -0.367256  0.282193   \n",
      "11 -0.390613  0.176006 -0.372885  0.037832 -0.409479  0.145525 -0.278403   \n",
      "12  0.434384 -0.415237  0.603129 -0.011017  0.592994 -0.610844  0.590898   \n",
      "13 -0.378498  0.380299 -0.476743  0.168661 -0.438328  0.681483 -0.364173   \n",
      "\n",
      "          7         8         9         10        11        12        13  \n",
      "0  -0.378590  0.609689  0.575652  0.273447 -0.390613  0.434384 -0.378498  \n",
      "1   0.650787 -0.311091 -0.303522 -0.403139  0.176006 -0.415237  0.380299  \n",
      "2  -0.725155  0.599226  0.701362  0.379284 -0.372885  0.603129 -0.476743  \n",
      "3  -0.083101 -0.024851 -0.051343 -0.122008  0.037832 -0.011017  0.168661  \n",
      "4  -0.777062  0.616535  0.673471  0.188160 -0.409479  0.592994 -0.438328  \n",
      "5   0.233970 -0.243990 -0.307904 -0.367256  0.145525 -0.610844  0.681483  \n",
      "6  -0.766670  0.462188  0.512746  0.282193 -0.278403  0.590898 -0.364173  \n",
      "7   1.000000 -0.511179 -0.543668 -0.243067  0.295995 -0.507075  0.253900  \n",
      "8  -0.511179  1.000000  0.922676  0.449908 -0.478245  0.490250 -0.375515  \n",
      "9  -0.543668  0.922676  1.000000  0.440499 -0.471777  0.534752 -0.448737  \n",
      "10 -0.243067  0.449908  0.440499  1.000000 -0.178060  0.365873 -0.493990  \n",
      "11  0.295995 -0.478245 -0.471777 -0.178060  1.000000 -0.376081  0.343953  \n",
      "12 -0.507075  0.490250  0.534752  0.365873 -0.376081  1.000000 -0.730793  \n",
      "13  0.253900 -0.375515 -0.448737 -0.493990  0.343953 -0.730793  1.000000  \n"
     ]
    }
   ],
   "source": [
    "# Compute Correlation Matrix\n",
    "\n",
    "data = pd.DataFrame(np.concatenate((X,Y.reshape(-1,1)),axis=1))\n",
    "print(data.corr())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fb37e19a-45b3-445d-82f2-265f70ff00d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop unecessary features\n",
    "\n",
    "X = X[:,[5,12]]\n",
    "X_test = X_test[:,[5,12]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f1a09569-d862-425e-b451-9963f073b8d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize, reshape and split into train, test and validation datasets.\n",
    "\n",
    "X_train,X_val,Y_train,Y_val = train_test_split(X,Y,test_size=0.1)\n",
    "\n",
    "Y_train = Y_train.reshape(1,Y_train.shape[0])\n",
    "Y_val = Y_val.reshape(1,Y_val.shape[0])\n",
    "\n",
    "X_train = (X_train-np.mean(X_train,axis=0))/np.std(X_train,axis=0)\n",
    "X_val = (X_val-np.mean(X_val,axis=0))/np.std(X_val,axis=0)\n",
    "X_test = (X_test-np.mean(X_test,axis=0))/np.std(X_test,axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "45498584-1add-4a98-a0f0-af536653b533",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After 10 epochs :    Training Loss = 104.77146714419219    Validation Loss = 137.91137374671368\n",
      "\n",
      "After 20 epochs :    Training Loss = 22.84498426459046    Validation Loss = 33.928385755268806\n",
      "\n",
      "After 30 epochs :    Training Loss = 13.427827935720217    Validation Loss = 25.858423756606648\n",
      "\n",
      "After 40 epochs :    Training Loss = 9.778861006924338    Validation Loss = 22.25159208853076\n",
      "\n",
      "After 50 epochs :    Training Loss = 8.791681412277331    Validation Loss = 21.32501596107805\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Loss :  8.791681412277331\n",
      "\n",
      "Validation Loss :  21.32501596107805\n"
     ]
    }
   ],
   "source": [
    "# Define and train the Deep Neural Network.\n",
    "\n",
    "model = Deep_Neural_Network()\n",
    "\n",
    "model.create(2,1,[10,20],output_type='regression',activation='relu',initializer='he')\n",
    "\n",
    "costs = model.train(X_train.T,Y_train,X_val.T,Y_val,optimizer='rmsprop',regularizer='l2',\n",
    "                    regularizer_lambda=0.1,mini_batch_size=32,epochs=50,print_loss_freq=10,\n",
    "                    learning_rate=0.002)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2d6e2232-281a-478f-9314-6def4f83fc57",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_cost, val_cost, train_acc, val_acc = costs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dc030cd2-9ea9-4b55-928e-9650720c731a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 2)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt = np.array([1.02237078, -1.12367874])\n",
    "\n",
    "ds = np.array([[ 0.11934137,  2.51324773], [-0.65939625,  0.58604286]])\n",
    "\n",
    "ds.shape\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "0867b1d5-21b5-4d98-84b4-550919887d90",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(363, 2)"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "1908c67a-4bbb-4d93-8764-899fa59b52a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "hasil ->  [[23.39143561 33.74300449]]\n"
     ]
    }
   ],
   "source": [
    "hasil = model.predict(ds)\n",
    "\n",
    "print(model.L)\n",
    "\n",
    "print(\"hasil -> \", hasil)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "21daffef-eb1f-4c2d-bdbf-f5a0a76fb7f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 7.2, 18.8, 19. , 27. , 22.2, 24.5, 31.2, 22.9, 20.5, 23.2, 18.6,\n",
       "       14.5, 17.8, 50. , 20.8, 24.3, 24.2, 19.8, 19.1, 22.7, 12. , 10.2,\n",
       "       20. , 18.5, 20.9, 23. , 27.5, 30.1,  9.5, 22. , 21.2, 14.1, 33.1,\n",
       "       23.4, 20.1,  7.4, 15.4, 23.8, 20.1, 24.5, 33. , 28.4, 14.1, 46.7,\n",
       "       32.5, 29.6, 28.4, 19.8, 20.2, 25. , 35.4, 20.3,  9.7, 14.5, 34.9,\n",
       "       26.6,  7.2, 50. , 32.4, 21.6, 29.8, 13.1, 27.5, 21.2, 23.1, 21.9,\n",
       "       13. , 23.2,  8.1,  5.6, 21.7, 29.6, 19.6,  7. , 26.4, 18.9, 20.9,\n",
       "       28.1, 35.4, 10.2, 24.3, 43.1, 17.6, 15.4, 16.2, 27.1, 21.4, 21.5,\n",
       "       22.4, 25. , 16.6, 18.6, 22. , 42.8, 35.1, 21.5, 36. , 21.9, 24.1,\n",
       "       50. , 26.7, 25. ])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "400c3022-ed04-4cd7-b7be-e85484378444",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
